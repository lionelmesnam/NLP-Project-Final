{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14205987,"sourceType":"datasetVersion","datasetId":9060648}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ======================================================\n# 0. IMPORT THƯ VIỆN & LOAD DATA UIT-VSMEC\n# ======================================================\nimport os\nimport re\nimport unicodedata\nimport random\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# Nếu đọc .xlsx lỗi thì bật dòng dưới (thường Kaggle có sẵn rồi)\n# !pip install --quiet openpyxl\n\n# Đường dẫn Kaggle dataset (thay bằng tên dataset nếu bạn đổi)\nDATA_DIR = \"/kaggle/input/uit-data-nhatnam2\"\n\ntrain_path = os.path.join(DATA_DIR, \"train_nor_811.xlsx\")\nvalid_path = os.path.join(DATA_DIR, \"valid_nor_811.xlsx\")\ntest_path  = os.path.join(DATA_DIR, \"test_nor_811.xlsx\")\n\ntrain_raw = pd.read_excel(train_path)\nvalid_raw = pd.read_excel(valid_path)\ntest_raw  = pd.read_excel(test_path)\n\nprint(\"Train raw shape:\", train_raw.shape)\nprint(\"Valid raw shape:\", valid_raw.shape)\nprint(\"Test  raw shape:\", test_raw.shape)\nprint(\"Columns:\", train_raw.columns.tolist())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:23.256205Z","iopub.execute_input":"2025-12-18T05:50:23.256395Z","iopub.status.idle":"2025-12-18T05:50:30.485712Z","shell.execute_reply.started":"2025-12-18T05:50:23.256375Z","shell.execute_reply":"2025-12-18T05:50:30.484850Z"}},"outputs":[{"name":"stdout","text":"Train raw shape: (5548, 3)\nValid raw shape: (686, 3)\nTest  raw shape: (693, 3)\nColumns: ['Unnamed: 0', 'Emotion', 'Sentence']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ======================================================\n# 1. PHÁT HIỆN CỘT TEXT & LABEL + TIỀN XỬ LÝ CƠ BẢN\n# ======================================================\n\ndef detect_text_and_label_cols(df):\n    cols = list(df.columns)\n\n    # ---- đoán cột text ----\n    text_candidates = [\n        \"text\", \"comment\", \"sentence\", \"content\", \"review\",\n        \"message\", \"utterance\", \"cmt\"\n    ]\n    label_candidates = [\n        \"label\", \"labels\", \"emotion\", \"sentiment\", \"class\", \"target\"\n    ]\n\n    # tìm cột text theo tên\n    text_col = None\n    lower_map = {c.lower(): c for c in cols}\n    for cand in text_candidates:\n        if cand in lower_map:\n            text_col = lower_map[cand]\n            break\n\n    # nếu không tìm được theo tên thì chọn cột string dài nhất\n    if text_col is None:\n        obj_cols = df.select_dtypes(include=[\"object\"]).columns\n        if len(obj_cols) == 0:\n            raise ValueError(\"Không tìm được cột text (không có cột kiểu object).\")\n        best_col = None\n        best_len = -1\n        for c in obj_cols:\n            avg_len = df[c].astype(str).str.len().mean()\n            if avg_len > best_len:\n                best_len = avg_len\n                best_col = c\n        text_col = best_col\n\n    # ---- đoán cột label ----\n    label_col = None\n    for cand in label_candidates:\n        if cand in lower_map and lower_map[cand] != text_col:\n            label_col = lower_map[cand]\n            break\n\n    # nếu không tìm được theo tên → chọn cột có ít giá trị khác nhau\n    if label_col is None:\n        candidate_cols = [\n            c for c in cols\n            if c != text_col and df[c].nunique() >= 2 and df[c].nunique() <= 50\n        ]\n        if not candidate_cols:\n            raise ValueError(\"Không tìm được cột label phù hợp.\")\n        best_col = None\n        best_nunique = 999999\n        for c in candidate_cols:\n            nunique = df[c].nunique()\n            if nunique < best_nunique:\n                best_nunique = nunique\n                best_col = c\n        label_col = best_col\n\n    return text_col, label_col\n\n\ndef prepare_df(df):\n    text_col, label_col = detect_text_and_label_cols(df)\n    print(f\"Detected text column:  {text_col}\")\n    print(f\"Detected label column: {label_col}\")\n\n    df = df[[text_col, label_col]].copy()\n    df.columns = [\"text\", \"label\"]\n    df = df.dropna(subset=[\"text\", \"label\"])\n\n    # ép kiểu string\n    df[\"text\"] = df[\"text\"].astype(str)\n    df[\"label\"] = df[\"label\"].astype(str)\n    return df\n\n\ntrain_df = prepare_df(train_raw)\nvalid_df = prepare_df(valid_raw)\ntest_df  = prepare_df(test_raw)\n\nprint(\"\\nLabel distribution (train):\")\nprint(train_df[\"label\"].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:30.487432Z","iopub.execute_input":"2025-12-18T05:50:30.487833Z","iopub.status.idle":"2025-12-18T05:50:30.520827Z","shell.execute_reply.started":"2025-12-18T05:50:30.487806Z","shell.execute_reply":"2025-12-18T05:50:30.520227Z"}},"outputs":[{"name":"stdout","text":"Detected text column:  Sentence\nDetected label column: Emotion\nDetected text column:  Sentence\nDetected label column: Emotion\nDetected text column:  Sentence\nDetected label column: Emotion\n\nLabel distribution (train):\nlabel\nEnjoyment    1558\nDisgust      1071\nOther        1021\nSadness       947\nAnger         391\nFear          318\nSurprise      242\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ======================================================\n# 1.1. HÀM CHUẨN HOÁ TEXT\n# ======================================================\nURL_RE = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n\ndef normalize_text(s: str) -> str:\n    s = unicodedata.normalize(\"NFC\", s)\n    # thay URL bằng token chung\n    s = URL_RE.sub(\" URL \", s)\n    # bỏ bớt khoảng trắng thừa\n    s = re.sub(r\"\\s+\", \" \", s)\n    return s.strip()\n\nfor df in (train_df, valid_df, test_df):\n    df[\"text\"] = df[\"text\"].map(normalize_text)\n\nprint(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:30.521826Z","iopub.execute_input":"2025-12-18T05:50:30.522150Z","iopub.status.idle":"2025-12-18T05:50:30.637397Z","shell.execute_reply.started":"2025-12-18T05:50:30.522115Z","shell.execute_reply":"2025-12-18T05:50:30.636853Z"}},"outputs":[{"name":"stdout","text":"                                                text      label\n0              cho mình xin bài nhạc tên là gì với ạ      Other\n1  cho đáng đời con quỷ . về nhà lôi con nhà mày ...    Disgust\n2  lo học đi . yêu đương lol gì hay lại thích học...    Disgust\n3    uớc gì sau này về già vẫn có thể như cụ này :))  Enjoyment\n4  mỗi lần có video của con là cứ coi đi coi lại ...  Enjoyment\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ======================================================\n# 1.2. SET SEED CHUNG (CHO TF-IDF + BiLSTM)\n# ======================================================\nimport numpy as np\nimport torch\nimport random\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:30.638126Z","iopub.execute_input":"2025-12-18T05:50:30.638372Z","iopub.status.idle":"2025-12-18T05:50:30.730537Z","shell.execute_reply.started":"2025-12-18T05:50:30.638340Z","shell.execute_reply":"2025-12-18T05:50:30.729942Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ======================================================\n# 2. BASELINE 1 – TF-IDF + LINEAR SVM (SCIKIT-LEARN)\n# ======================================================\n\n# Lấy dữ liệu\nX_train = train_df[\"text\"].tolist()\ny_train = train_df[\"label\"].tolist()\n\nX_valid = valid_df[\"text\"].tolist()\ny_valid = valid_df[\"label\"].tolist()\n\nX_test  = test_df[\"text\"].tolist()\ny_test  = test_df[\"label\"].tolist()\n\n# Pipeline: TF-IDF (uni+bi-gram) -> Linear SVM\nsvm_pipeline = Pipeline([\n    (\"tfidf\", TfidfVectorizer(\n        ngram_range=(1, 2),   # unigram + bigram\n        min_df=2,\n        max_df=0.95,\n        max_features=50000,\n        sublinear_tf=True\n    )),\n    (\"clf\", LinearSVC(C=1.0))\n])\n\n# Huấn luyện\nsvm_pipeline.fit(X_train, y_train)\n\ndef eval_split_svm(name, X, y_true):\n    y_pred = svm_pipeline.predict(X)\n    acc = accuracy_score(y_true, y_pred)\n    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    weighted_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n\n    print(f\"\\n===== TF-IDF + SVM - {name} =====\")\n    print(f\"Accuracy   : {acc:.4f}\")\n    print(f\"Macro F1   : {macro_f1:.4f}\")\n    print(f\"Weighted F1: {weighted_f1:.4f}\")\n    print(\"\\nClassification report:\")\n    print(classification_report(y_true, y_pred))\n\n# Đánh giá trên train / valid / test\neval_split_svm(\"Train\", X_train, y_train)\neval_split_svm(\"Valid\", X_valid, y_valid)\neval_split_svm(\"Test\",  X_test,  y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:30.731403Z","iopub.execute_input":"2025-12-18T05:50:30.731708Z","iopub.status.idle":"2025-12-18T05:50:31.292342Z","shell.execute_reply.started":"2025-12-18T05:50:30.731685Z","shell.execute_reply":"2025-12-18T05:50:31.291658Z"}},"outputs":[{"name":"stdout","text":"\n===== TF-IDF + SVM - Train =====\nAccuracy   : 0.9941\nMacro F1   : 0.9937\nWeighted F1: 0.9941\n\nClassification report:\n              precision    recall  f1-score   support\n\n       Anger       1.00      0.99      1.00       391\n     Disgust       0.99      0.99      0.99      1071\n   Enjoyment       0.99      1.00      0.99      1558\n        Fear       0.99      0.99      0.99       318\n       Other       1.00      0.99      0.99      1021\n     Sadness       1.00      1.00      1.00       947\n    Surprise       0.99      0.99      0.99       242\n\n    accuracy                           0.99      5548\n   macro avg       0.99      0.99      0.99      5548\nweighted avg       0.99      0.99      0.99      5548\n\n\n===== TF-IDF + SVM - Valid =====\nAccuracy   : 0.5569\nMacro F1   : 0.5056\nWeighted F1: 0.5529\n\nClassification report:\n              precision    recall  f1-score   support\n\n       Anger       0.47      0.39      0.43        49\n     Disgust       0.56      0.59      0.57       135\n   Enjoyment       0.70      0.71      0.71       214\n        Fear       0.67      0.52      0.58        31\n       Other       0.44      0.38      0.41       141\n     Sadness       0.44      0.62      0.51        86\n    Surprise       0.42      0.27      0.33        30\n\n    accuracy                           0.56       686\n   macro avg       0.53      0.50      0.51       686\nweighted avg       0.56      0.56      0.55       686\n\n\n===== TF-IDF + SVM - Test =====\nAccuracy   : 0.5368\nMacro F1   : 0.5111\nWeighted F1: 0.5325\n\nClassification report:\n              precision    recall  f1-score   support\n\n       Anger       0.38      0.25      0.30        40\n     Disgust       0.46      0.59      0.51       132\n   Enjoyment       0.60      0.66      0.63       193\n        Fear       0.69      0.63      0.66        46\n       Other       0.45      0.40      0.42       129\n     Sadness       0.58      0.54      0.56       116\n    Surprise       0.70      0.38      0.49        37\n\n    accuracy                           0.54       693\n   macro avg       0.55      0.49      0.51       693\nweighted avg       0.54      0.54      0.53       693\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ======================================================\n# 3. BASELINE 2 – BiLSTM + WORD EMBEDDING (PYTORCH)\n# ======================================================\n\n# 3.1. Xây vocab từ train\ndef simple_tokenize(text):\n    # ở đây dùng split theo khoảng trắng vì text đã clean\n    return text.strip().split()\n\ncounter = Counter()\nfor t in train_df[\"text\"]:\n    counter.update(simple_tokenize(t))\n\nmax_vocab_size = 30000\nmost_common = counter.most_common(max_vocab_size - 2)  # trừ <pad>, <unk>\n\nitos = [\"<pad>\", \"<unk>\"] + [w for w, _ in most_common]\nstoi = {w: i for i, w in enumerate(itos)}\n\npad_idx = stoi[\"<pad>\"]\nunk_idx = stoi[\"<unk>\"]\nvocab_size = len(itos)\nprint(\"Vocab size:\", vocab_size)\n\n# 3.2. Encode câu -> sequence id (padding)\ndef encode_sentence(text, max_len=50):\n    tokens = simple_tokenize(text)\n    ids = [stoi.get(tok, unk_idx) for tok in tokens][:max_len]\n    if len(ids) < max_len:\n        ids += [pad_idx] * (max_len - len(ids))\n    return ids\n\nmax_len = 128   # có thể chỉnh sau nếu muốn\n\n# 3.3. Mapping label -> id (giữ cố định để dùng lại)\nlabel_list = sorted(train_df[\"label\"].unique())\nlabel2id = {lb: i for i, lb in enumerate(label_list)}\nid2label = {i: lb for lb, i in label2id.items()}\nnum_labels = len(label_list)\nprint(\"Labels:\", label2id)\n\n\nclass VSMECDataset(Dataset):\n    def __init__(self, df, max_len):\n        self.texts = df[\"text\"].tolist()\n        self.labels = [label2id[lb] for lb in df[\"label\"].tolist()]\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(encode_sentence(self.texts[idx], max_len=self.max_len),\n                         dtype=torch.long)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return x, y\n\ntrain_dataset = VSMECDataset(train_df, max_len=max_len)\nvalid_dataset = VSMECDataset(valid_df, max_len=max_len)\ntest_dataset  = VSMECDataset(test_df,  max_len=max_len)\n\nbatch_size = 64\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:31.294064Z","iopub.execute_input":"2025-12-18T05:50:31.294648Z","iopub.status.idle":"2025-12-18T05:50:31.327780Z","shell.execute_reply.started":"2025-12-18T05:50:31.294621Z","shell.execute_reply":"2025-12-18T05:50:31.327257Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 4644\nLabels: {'Anger': 0, 'Disgust': 1, 'Enjoyment': 2, 'Fear': 3, 'Other': 4, 'Sadness': 5, 'Surprise': 6}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 3.4. Định nghĩa mô hình BiLSTM\n\nclass BiLSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(\n            input_size=embed_dim,\n            hidden_size=hidden_dim,\n            num_layers=1,\n            bidirectional=True,\n            batch_first=True,\n        )\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n\n    def forward(self, input_ids):\n        x = self.embedding(input_ids)         # (B, T, E)\n        output, (h_n, c_n) = self.lstm(x)     # h_n: (2, B, H) vì bidirectional & 1 layer\n        h_forward = h_n[-2]                   # (B, H)\n        h_backward = h_n[-1]                  # (B, H)\n        h_cat = torch.cat([h_forward, h_backward], dim=1)  # (B, 2H)\n        logits = self.fc(self.dropout(h_cat))             # (B, num_labels)\n        return logits\n\nembed_dim = 200\nhidden_dim = 128\n\nmodel_bilstm = BiLSTMClassifier(\n    vocab_size=vocab_size,\n    embed_dim=embed_dim,\n    hidden_dim=hidden_dim,\n    num_labels=num_labels,\n    pad_idx=pad_idx,\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_bilstm.parameters(), lr=1e-3)\n\nprint(model_bilstm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:31.328588Z","iopub.execute_input":"2025-12-18T05:50:31.328848Z","iopub.status.idle":"2025-12-18T05:50:34.459396Z","shell.execute_reply.started":"2025-12-18T05:50:31.328826Z","shell.execute_reply":"2025-12-18T05:50:34.458645Z"}},"outputs":[{"name":"stdout","text":"BiLSTMClassifier(\n  (embedding): Embedding(4644, 200, padding_idx=0)\n  (lstm): LSTM(200, 128, batch_first=True, bidirectional=True)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=256, out_features=7, bias=True)\n)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 3.5. Hàm evaluate cho BiLSTM\n\ndef evaluate_bilstm(model, data_loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for x_batch, y_batch in data_loader:\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n            logits = model(x_batch)\n            preds = torch.argmax(logits, dim=-1)\n            all_preds.extend(preds.cpu().numpy().tolist())\n            all_labels.extend(y_batch.cpu().numpy().tolist())\n    acc = accuracy_score(all_labels, all_preds)\n    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n    weighted_f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n    return acc, macro_f1, weighted_f1, np.array(all_labels), np.array(all_preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:34.460406Z","iopub.execute_input":"2025-12-18T05:50:34.460839Z","iopub.status.idle":"2025-12-18T05:50:34.466702Z","shell.execute_reply.started":"2025-12-18T05:50:34.460804Z","shell.execute_reply":"2025-12-18T05:50:34.465982Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# 3.6. Train loop + Early Stopping (theo macro F1 valid)\n\nfrom copy import deepcopy\n\nn_epochs = 20\nbest_val_macro_f1 = 0.0\nbest_state_dict = None\npatience = 3\npatience_counter = 0\n\nfor epoch in range(1, n_epochs + 1):\n    model_bilstm.train()\n    total_loss = 0.0\n\n    for x_batch, y_batch in train_loader:\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        logits = model_bilstm(x_batch)\n        loss = criterion(logits, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * x_batch.size(0)\n\n    train_loss = total_loss / len(train_loader.dataset)\n    val_acc, val_macro_f1, val_weighted_f1, _, _ = evaluate_bilstm(model_bilstm, valid_loader)\n\n    print(f\"Epoch {epoch:02d} | \"\n          f\"train_loss={train_loss:.4f} | \"\n          f\"val_acc={val_acc:.4f} | \"\n          f\"val_macro_f1={val_macro_f1:.4f} | \"\n          f\"val_weighted_f1={val_weighted_f1:.4f}\")\n\n    # Early stopping\n    if val_macro_f1 > best_val_macro_f1:\n        best_val_macro_f1 = val_macro_f1\n        best_state_dict = deepcopy(model_bilstm.state_dict())\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping!\")\n            break\n\n# Load best weights\nif best_state_dict is not None:\n    model_bilstm.load_state_dict(best_state_dict)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:34.467528Z","iopub.execute_input":"2025-12-18T05:50:34.467742Z","iopub.status.idle":"2025-12-18T05:50:47.812316Z","shell.execute_reply.started":"2025-12-18T05:50:34.467719Z","shell.execute_reply":"2025-12-18T05:50:47.811673Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | train_loss=1.7607 | val_acc=0.3557 | val_macro_f1=0.1626 | val_weighted_f1=0.2748\nEpoch 02 | train_loss=1.5159 | val_acc=0.4184 | val_macro_f1=0.2964 | val_weighted_f1=0.3886\nEpoch 03 | train_loss=1.3495 | val_acc=0.4475 | val_macro_f1=0.3427 | val_weighted_f1=0.4337\nEpoch 04 | train_loss=1.0820 | val_acc=0.4504 | val_macro_f1=0.3918 | val_weighted_f1=0.4472\nEpoch 05 | train_loss=0.8464 | val_acc=0.4927 | val_macro_f1=0.4251 | val_weighted_f1=0.4842\nEpoch 06 | train_loss=0.6583 | val_acc=0.4913 | val_macro_f1=0.4267 | val_weighted_f1=0.4867\nEpoch 07 | train_loss=0.4899 | val_acc=0.4971 | val_macro_f1=0.4306 | val_weighted_f1=0.4929\nEpoch 08 | train_loss=0.3472 | val_acc=0.5102 | val_macro_f1=0.4529 | val_weighted_f1=0.5026\nEpoch 09 | train_loss=0.2491 | val_acc=0.5029 | val_macro_f1=0.4264 | val_weighted_f1=0.4929\nEpoch 10 | train_loss=0.1748 | val_acc=0.5000 | val_macro_f1=0.4469 | val_weighted_f1=0.4961\nEpoch 11 | train_loss=0.1330 | val_acc=0.5102 | val_macro_f1=0.4555 | val_weighted_f1=0.5096\nEpoch 12 | train_loss=0.0913 | val_acc=0.4898 | val_macro_f1=0.4529 | val_weighted_f1=0.4919\nEpoch 13 | train_loss=0.0981 | val_acc=0.5146 | val_macro_f1=0.4537 | val_weighted_f1=0.5037\nEpoch 14 | train_loss=0.0668 | val_acc=0.5000 | val_macro_f1=0.4538 | val_weighted_f1=0.4894\nEarly stopping!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 3.7. ĐÁNH GIÁ BiLSTM TRÊN TEST\n\ntest_acc, test_macro_f1, test_weighted_f1, y_true, y_pred = evaluate_bilstm(model_bilstm, test_loader)\n\nprint(\"\\n===== BiLSTM Test Results =====\")\nprint(f\"Accuracy   : {test_acc:.4f}\")\nprint(f\"Macro F1   : {test_macro_f1:.4f}\")\nprint(f\"Weighted F1: {test_weighted_f1:.4f}\")\n\nprint(\"\\nClassification report (BiLSTM):\")\nprint(classification_report(\n    y_true,\n    y_pred,\n    target_names=[id2label[i] for i in range(num_labels)]\n))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T05:50:47.813236Z","iopub.execute_input":"2025-12-18T05:50:47.813494Z","iopub.status.idle":"2025-12-18T05:50:47.880661Z","shell.execute_reply.started":"2025-12-18T05:50:47.813471Z","shell.execute_reply":"2025-12-18T05:50:47.880078Z"}},"outputs":[{"name":"stdout","text":"\n===== BiLSTM Test Results =====\nAccuracy   : 0.4675\nMacro F1   : 0.4271\nWeighted F1: 0.4648\n\nClassification report (BiLSTM):\n              precision    recall  f1-score   support\n\n       Anger       0.33      0.25      0.29        40\n     Disgust       0.44      0.49      0.46       132\n   Enjoyment       0.56      0.54      0.55       193\n        Fear       0.53      0.50      0.52        46\n       Other       0.37      0.45      0.41       129\n     Sadness       0.49      0.48      0.48       116\n    Surprise       0.54      0.19      0.28        37\n\n    accuracy                           0.47       693\n   macro avg       0.47      0.42      0.43       693\nweighted avg       0.47      0.47      0.46       693\n\n","output_type":"stream"}],"execution_count":10}]}